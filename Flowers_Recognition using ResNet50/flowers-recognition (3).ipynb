{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **Objective:**\n\nThe objective of this project is to classify given data as rose and daisy using CNN models.","metadata":{}},{"cell_type":"code","source":"# Load the following libraries.\n\nimport sys\nimport time\nimport cv2\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nimport os\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.python.keras.utils import np_utils\nfrom tensorflow.python.keras.models import Sequential, Model\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D \nfrom tensorflow.python.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization\nfrom tensorflow.keras.utils import get_file","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:53:45.056339Z","iopub.execute_input":"2021-10-04T04:53:45.056936Z","iopub.status.idle":"2021-10-04T04:53:50.562734Z","shell.execute_reply.started":"2021-10-04T04:53:45.056847Z","shell.execute_reply":"2021-10-04T04:53:50.561950Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Load the data.\n\nDATASET_PATH = '../input/flowers-recognition/flowers'\n\ncategories = ['daisy', 'rose']","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:54:17.763336Z","iopub.execute_input":"2021-10-04T04:54:17.763603Z","iopub.status.idle":"2021-10-04T04:54:17.767593Z","shell.execute_reply.started":"2021-10-04T04:54:17.763575Z","shell.execute_reply":"2021-10-04T04:54:17.766604Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load the file names.\n\nfnames = []\nfor category in categories:\n    flower_folder = os.path.join(DATASET_PATH, category)\n    file_names = os.listdir(flower_folder)\n    full_path = [os.path.join(flower_folder, file_name) for file_name in file_names]\n    fnames.append(full_path)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:54:23.129301Z","iopub.execute_input":"2021-10-04T04:54:23.129974Z","iopub.status.idle":"2021-10-04T04:54:23.533363Z","shell.execute_reply.started":"2021-10-04T04:54:23.129938Z","shell.execute_reply":"2021-10-04T04:54:23.532611Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Determine length of each category.\n\nprint('length for each category:', [len(f) for f in fnames])","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:54:28.957914Z","iopub.execute_input":"2021-10-04T04:54:28.958480Z","iopub.status.idle":"2021-10-04T04:54:28.963632Z","shell.execute_reply.started":"2021-10-04T04:54:28.958446Z","shell.execute_reply":"2021-10-04T04:54:28.962743Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Load images.\n\nimages = []\nfor names in fnames:\n    one_category_images = [cv2.imread(name) for name in names if (cv2.imread(name)) is not None]\n    images.append(one_category_images)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:54:44.138216Z","iopub.execute_input":"2021-10-04T04:54:44.138513Z","iopub.status.idle":"2021-10-04T04:55:07.056440Z","shell.execute_reply.started":"2021-10-04T04:54:44.138483Z","shell.execute_reply":"2021-10-04T04:55:07.055660Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Determine shape of images.\n\nfor i,imgs in enumerate(images):\n    shapes = [img.shape for img in imgs]\n    widths = [shape[0] for shape in shapes]\n    heights = [shape[1] for shape in shapes]\n    print('%d,%d is the min shape for %s' % (np.min(widths), np.min(heights), categories[i]))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:55:07.057939Z","iopub.execute_input":"2021-10-04T04:55:07.058219Z","iopub.status.idle":"2021-10-04T04:55:07.069705Z","shell.execute_reply.started":"2021-10-04T04:55:07.058177Z","shell.execute_reply":"2021-10-04T04:55:07.068449Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Create a function to convert BGR format to RGB format.\n\ndef cvtRGB(img):\n    return cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:55:16.013721Z","iopub.execute_input":"2021-10-04T04:55:16.013997Z","iopub.status.idle":"2021-10-04T04:55:16.020238Z","shell.execute_reply.started":"2021-10-04T04:55:16.013954Z","shell.execute_reply":"2021-10-04T04:55:16.017850Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Plotting images.\n\nplt.figure(figsize = (15,10))\nfor i, imgs in enumerate(images):\n    plt.subplot(2, 3, i+1)\n    idx = np.random.randint(len(imgs))\n    plt.imshow(cvtRGB(imgs[idx]))\n    plt.grid('off')\n    plt.title(categories[i] + ' ' + str(idx))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:55:18.182918Z","iopub.execute_input":"2021-10-04T04:55:18.183566Z","iopub.status.idle":"2021-10-04T04:55:18.584175Z","shell.execute_reply.started":"2021-10-04T04:55:18.183524Z","shell.execute_reply":"2021-10-04T04:55:18.583494Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Apply resize to all images.\n\nimg_width, img_height = 256, 256\nresized_images = []\nfor i,imgs in enumerate(images):\n    resized_images.append([cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_CUBIC) for img in imgs])","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:55:29.689239Z","iopub.execute_input":"2021-10-04T04:55:29.689524Z","iopub.status.idle":"2021-10-04T04:55:30.185768Z","shell.execute_reply.started":"2021-10-04T04:55:29.689494Z","shell.execute_reply":"2021-10-04T04:55:30.185052Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Splitting data to train and test data.\n\ntrain_images = []\nval_images = []\nfor imgs in resized_images:\n    train, test = train_test_split(imgs, train_size = 0.8, test_size = 0.2)\n    train_images.append(train)\n    val_images.append(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:55:53.098346Z","iopub.execute_input":"2021-10-04T04:55:53.098616Z","iopub.status.idle":"2021-10-04T04:55:53.108311Z","shell.execute_reply.started":"2021-10-04T04:55:53.098588Z","shell.execute_reply":"2021-10-04T04:55:53.107548Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Create labels for all images.\n\nlen_train_images = [len(imgs) for imgs in train_images]\nprint(len_train_images)\nprint('sum of train images:', np.sum(len_train_images))\ntrain_categories = np.zeros((np.sum(len_train_images)), dtype = 'uint8')\nfor i in range(5):\n    if i is 0:\n        train_categories[:len_train_images[i]] = i\n    else:\n        train_categories[np.sum(len_train_images[:i]):np.sum(len_train_images[:i+1])] = i\n        \nlen_val_images = [len(imgs) for imgs in val_images]\nprint(len_val_images)\nprint('sum of val_images:', np.sum(len_val_images))\nval_categories = np.zeros((np.sum(len_val_images)), dtype = 'uint8')\nfor i in range(5):\n    if i is 0:\n        val_categories[:len_val_images[i]] = i\n    else:\n        val_categories[np.sum(len_val_images[:i]):np.sum(len_val_images[:i+1])] = i","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:56:00.699148Z","iopub.execute_input":"2021-10-04T04:56:00.699855Z","iopub.status.idle":"2021-10-04T04:56:00.712291Z","shell.execute_reply.started":"2021-10-04T04:56:00.699814Z","shell.execute_reply":"2021-10-04T04:56:00.711474Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Convert images to numpy arrays.\n\ntmp_train_imgs = []\ntmp_val_imgs = []\nfor imgs in train_images:\n    tmp_train_imgs += imgs\nfor imgs in val_images:\n    tmp_val_imgs += imgs\ntrain_images = np.array(tmp_train_imgs)\nval_images = np.array(tmp_val_imgs)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:56:07.198852Z","iopub.execute_input":"2021-10-04T04:56:07.199569Z","iopub.status.idle":"2021-10-04T04:56:07.294337Z","shell.execute_reply.started":"2021-10-04T04:56:07.199535Z","shell.execute_reply":"2021-10-04T04:56:07.293580Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Convert class labels to binary class labels.\n\nprint('Before converting')\nprint('train data:', train_images.shape)\nprint('train labels:', train_categories.shape)\n\ntrain_data = train_images.astype('float32')\nval_data = val_images.astype('float32')\ntrain_labels = np_utils.to_categorical(train_categories, len(categories))\nval_labels = np_utils.to_categorical(val_categories, len(categories))\nprint()\nprint('After converting')\nprint('train data:', train_data.shape)\nprint('train labels:', train_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:56:18.068776Z","iopub.execute_input":"2021-10-04T04:56:18.069462Z","iopub.status.idle":"2021-10-04T04:56:18.378543Z","shell.execute_reply.started":"2021-10-04T04:56:18.069430Z","shell.execute_reply":"2021-10-04T04:56:18.377798Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Shuffle the data.\n\nseed = 100\nnp.random.seed(seed)\nnp.random.shuffle(train_data)\nnp.random.seed(seed)\nnp.random.shuffle(train_labels)\nnp.random.seed(seed)\nnp.random.shuffle(val_data)\nnp.random.seed(seed)\nnp.random.shuffle(val_labels)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:56:28.219166Z","iopub.execute_input":"2021-10-04T04:56:28.219508Z","iopub.status.idle":"2021-10-04T04:56:28.630849Z","shell.execute_reply.started":"2021-10-04T04:56:28.219468Z","shell.execute_reply":"2021-10-04T04:56:28.630071Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# View shape of train_data and test_data.\n\nprint('shape of train data:', train_data.shape)\nprint('shape of train labels:', train_labels.shape)\nprint('shape of val data:', val_data.shape)\nprint('shape of val labels:', val_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:56:34.079085Z","iopub.execute_input":"2021-10-04T04:56:34.079721Z","iopub.status.idle":"2021-10-04T04:56:34.088417Z","shell.execute_reply.started":"2021-10-04T04:56:34.079684Z","shell.execute_reply":"2021-10-04T04:56:34.087475Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### **Model Building**","metadata":{}},{"cell_type":"markdown","source":"### **1. Create a CNN model**","metadata":{}},{"cell_type":"code","source":"def create_model_from_scratch():\n\n    model = Sequential()\n    model.add(Conv2D(32, (3,3), padding = 'same', input_shape = train_data.shape[1:], activation = 'relu', name = 'conv_1'))\n    model.add(Conv2D(32, (3,3), activation = 'relu', name = 'conv_2'))\n    model.add(MaxPooling2D(pool_size = (2,2), name = 'maxpool_1'))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(64, (3,3), padding = 'same', activation = 'relu', name = 'conv_3'))\n    model.add(Conv2D(64, (3,3), activation = 'relu', name = 'conv_4'))\n    model.add(MaxPooling2D(pool_size = (2,2), name = 'maxpool_2'))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(128, (3,3), padding = 'same', activation = 'relu', name = 'conv_5'))\n    model.add(Conv2D(128, (3,3), activation = 'relu', name = 'conv_6'))\n    model.add(MaxPooling2D(pool_size = (2,2), name = 'maxpool_3'))\n\n    model.add(Flatten())\n    model.add(Dense(512, activation = 'relu', name = 'dense_1'))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation = 'relu', name = 'dense_2'))\n    model.add(Dense(len(categories), name = 'output'))\n    model.add(Activation('softmax'))\n\n    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc']) \n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:56:43.012013Z","iopub.execute_input":"2021-10-04T04:56:43.012407Z","iopub.status.idle":"2021-10-04T04:56:43.028812Z","shell.execute_reply.started":"2021-10-04T04:56:43.012345Z","shell.execute_reply":"2021-10-04T04:56:43.028184Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### **2. Create a VGG19 model**","metadata":{}},{"cell_type":"code","source":"def create_model_from_VGG19():\n    \n    model = VGG19(weights = \"imagenet\", include_top = False, input_shape = (img_width, img_height, 3))\n    \n    # Freezing the first 5 layers.\n    \n    for layer in model.layers[:1]:\n      layer.trainable = False\n      \n    # Adding custom Layers. \n    \n    x = model.output\n    x = Flatten()(x)\n    x = Dense(1024, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    x = Dense(1024, activation=\"relu\")(x)\n    predictions = Dense(len(categories), activation = \"softmax\")(x)\n    \n    # creating the final model.\n    \n    final_model = Model(inputs = model.input, outputs = predictions)\n    \n    final_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc']) \n    \n    return final_model","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:56:50.191092Z","iopub.execute_input":"2021-10-04T04:56:50.192068Z","iopub.status.idle":"2021-10-04T04:56:50.200112Z","shell.execute_reply.started":"2021-10-04T04:56:50.192025Z","shell.execute_reply":"2021-10-04T04:56:50.198721Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"### **3. Create ResNet50 model**","metadata":{}},{"cell_type":"code","source":"def create_model_from_ResNet50():\n\n    model = Sequential()\n\n    model.add(ResNet50(include_top = False, pooling = 'avg', weights = 'imagenet'))\n    model.add(Flatten())\n    model.add(BatchNormalization())\n    model.add(Dense(2048, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dense(1024, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dense(len(categories), activation = 'softmax'))\n\n    model.layers[0].trainable = False\n    \n    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc']) \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:30:20.495895Z","iopub.execute_input":"2021-10-04T05:30:20.496608Z","iopub.status.idle":"2021-10-04T05:30:20.503411Z","shell.execute_reply.started":"2021-10-04T05:30:20.496574Z","shell.execute_reply":"2021-10-04T05:30:20.502600Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# View model summary.\n\nmodel_scratch = create_model_from_scratch()\n\nmodel_scratch.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:57:22.072733Z","iopub.execute_input":"2021-10-04T04:57:22.073029Z","iopub.status.idle":"2021-10-04T04:57:24.215487Z","shell.execute_reply.started":"2021-10-04T04:57:22.072992Z","shell.execute_reply":"2021-10-04T04:57:24.214756Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# View model summary.\n\nmodel_VGG19 = create_model_from_VGG19()\n\nmodel_VGG19.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T04:57:33.432950Z","iopub.execute_input":"2021-10-04T04:57:33.433563Z","iopub.status.idle":"2021-10-04T04:57:34.290407Z","shell.execute_reply.started":"2021-10-04T04:57:33.433526Z","shell.execute_reply":"2021-10-04T04:57:34.289649Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# View model summary.\n\nmodel_ResNet50 = create_model_from_ResNet50()\n\nmodel_ResNet50.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:30:35.274735Z","iopub.execute_input":"2021-10-04T05:30:35.275341Z","iopub.status.idle":"2021-10-04T05:30:37.823058Z","shell.execute_reply.started":"2021-10-04T05:30:35.275301Z","shell.execute_reply":"2021-10-04T05:30:37.822284Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### **Data Augmentation**","metadata":{}},{"cell_type":"code","source":"# Adding rescale, rotation_range, width_shift_range, height_shift_range,\n# shear_range, zoom_range, and horizontal flip to ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n    rescale = 1./255,\n    rotation_range = 40,\n    width_shift_range = 0.4,\n    height_shift_range = 0.4,\n    shear_range = 0.2,\n    zoom_range = 0.3,\n    horizontal_flip = True\n)\n\n\nval_datagen = ImageDataGenerator(\n    rescale = 1./255,\n    rotation_range = 40,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True\n)\n\n# Flow training images in batches of 32 using train_datagen generator.\n\ntrain_generator = train_datagen.flow(\n    train_data,\n    train_labels,\n    batch_size = 32\n)\n\nval_generator = val_datagen.flow(\n    val_data,\n    val_labels,\n    batch_size = 32\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:31:00.720586Z","iopub.execute_input":"2021-10-04T05:31:00.720852Z","iopub.status.idle":"2021-10-04T05:31:00.729013Z","shell.execute_reply.started":"2021-10-04T05:31:00.720823Z","shell.execute_reply":"2021-10-04T05:31:00.728015Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### **Train the model**","metadata":{}},{"cell_type":"code","source":"batch_size = 32","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:32:29.101281Z","iopub.execute_input":"2021-10-04T05:32:29.101560Z","iopub.status.idle":"2021-10-04T05:32:29.105494Z","shell.execute_reply.started":"2021-10-04T05:32:29.101532Z","shell.execute_reply":"2021-10-04T05:32:29.104774Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nmodel_scratch_info = model_scratch.fit_generator(\n    generator = train_generator, \n    steps_per_epoch = len(train_data)/batch_size,   \n    epochs = 10, \n    validation_steps = len(val_data)/batch_size, \n    validation_data = val_generator, \n    verbose = 2\n)\n\nend = time.time()\nduration = end - start\nprint ('\\n model_scratch took %0.2f seconds (%0.1f minutes) to train for %d epochs'%(duration, duration/60, 10) )","metadata":{"execution":{"iopub.status.busy":"2021-10-04T06:01:23.492116Z","iopub.execute_input":"2021-10-04T06:01:23.492731Z","iopub.status.idle":"2021-10-04T06:04:47.296633Z","shell.execute_reply.started":"2021-10-04T06:01:23.492696Z","shell.execute_reply":"2021-10-04T06:04:47.295874Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nmodel_VGG19_info = model_VGG19.fit_generator(\n    generator = train_generator, \n    steps_per_epoch = len(train_data)/batch_size,   \n    epochs = 10, \n    validation_steps = len(val_data)/batch_size, \n    validation_data = val_generator,\n    verbose = 2\n)\n\nend = time.time()\nduration = end - start\nprint ('\\n model_VGG19 took %0.2f seconds (%0.1f minutes) to train for %d epochs'%(duration, duration/60, 10) )","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:36:32.875070Z","iopub.execute_input":"2021-10-04T05:36:32.875593Z","iopub.status.idle":"2021-10-04T05:40:22.124126Z","shell.execute_reply.started":"2021-10-04T05:36:32.875553Z","shell.execute_reply":"2021-10-04T05:40:22.123430Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nmodel_ResNet50_info = model_ResNet50.fit_generator(\n    generator = train_generator, \n    steps_per_epoch = len(train_data)/batch_size,   \n    epochs = 30, \n    validation_steps = len(val_data)/batch_size, \n    validation_data = val_generator, \n    verbose = 2\n)\n\nend = time.time()\nduration = end - start\nprint ('\\n model_ResNet50 took %0.2f seconds (%0.1f minutes) to train for %d epochs'%(duration, duration/60, 30))","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:40:45.955561Z","iopub.execute_input":"2021-10-04T05:40:45.955830Z","iopub.status.idle":"2021-10-04T05:51:22.416203Z","shell.execute_reply.started":"2021-10-04T05:40:45.955802Z","shell.execute_reply":"2021-10-04T05:51:22.415083Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### **Predict the test data**","metadata":{}},{"cell_type":"code","source":"def predict_one_image(img, model):\n  img = cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_CUBIC)\n  img = np.reshape(img, (1, img_width, img_height, 3))\n  img = img/255.\n  pred = model.predict(img)\n  class_num = np.argmax(pred)\n  return class_num, np.max(pred)","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:57:06.021651Z","iopub.execute_input":"2021-10-04T05:57:06.021935Z","iopub.status.idle":"2021-10-04T05:57:06.027651Z","shell.execute_reply.started":"2021-10-04T05:57:06.021908Z","shell.execute_reply":"2021-10-04T05:57:06.026798Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# Predict test data using scratch_model.\n\ntest_img = cv2.imread('../input/flowers-recognition/flowers/rose/6125332325_b768e08bd9_n.jpg')\npred, probability = predict_one_image(test_img, model_scratch)\nprint('%s %d%%' % (categories[pred], round(probability, 2) * 100))\n_, ax = plt.subplots(1)\nplt.imshow(cvtRGB(test_img))\n# Turn off tick labels\nax.set_yticklabels([])\nax.set_xticklabels([])\nplt.grid('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T06:06:10.153560Z","iopub.execute_input":"2021-10-04T06:06:10.153825Z","iopub.status.idle":"2021-10-04T06:06:10.419171Z","shell.execute_reply.started":"2021-10-04T06:06:10.153797Z","shell.execute_reply":"2021-10-04T06:06:10.415752Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Predict test data using VGG19 model.\n\ntest_img = cv2.imread('../input/flowers-recognition/flowers/rose/6125332325_b768e08bd9_n.jpg')\npred, probability = predict_one_image(test_img, model_VGG19)\nprint('%s %d%%' % (categories[pred], round(probability, 2) * 100))\n_, ax = plt.subplots(1)\nplt.imshow(cvtRGB(test_img))\n# Turn off tick labels\nax.set_yticklabels([])\nax.set_xticklabels([])\nplt.grid('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:59:36.888582Z","iopub.execute_input":"2021-10-04T05:59:36.889303Z","iopub.status.idle":"2021-10-04T05:59:37.600553Z","shell.execute_reply.started":"2021-10-04T05:59:36.889264Z","shell.execute_reply":"2021-10-04T05:59:37.599853Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"# Predict test data using ResNet50 model.\n\ntest_img = cv2.imread('../input/flowers-recognition/flowers/rose/6125332325_b768e08bd9_n.jpg')\npred, probability = predict_one_image(test_img, model_ResNet50)\nprint('%s %d%%' % (categories[pred], round(probability, 2) * 100))\n_, ax = plt.subplots(1)\nplt.imshow(cvtRGB(test_img))\n# Turn off tick labels\nax.set_yticklabels([])\nax.set_xticklabels([])\nplt.grid('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-04T05:58:12.127585Z","iopub.execute_input":"2021-10-04T05:58:12.127863Z","iopub.status.idle":"2021-10-04T05:58:13.328587Z","shell.execute_reply.started":"2021-10-04T05:58:12.127832Z","shell.execute_reply":"2021-10-04T05:58:13.327770Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"### **Conclusion:**\n\nResNet50 is performing best with an accuracy of 99% when compared to other models.","metadata":{}}]}