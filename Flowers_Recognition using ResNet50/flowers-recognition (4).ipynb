{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### **Objective:**\n\nThe objective of this project is to classify given data as rose and daisy using CNN models.","metadata":{}},{"cell_type":"code","source":"# Load the following libraries.\n\nimport numpy as np\nnp.random.seed(1337)\nimport sys\nimport time\nimport cv2\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nimport os\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.python.keras.utils import np_utils\nfrom tensorflow.python.keras.models import Sequential, Model\nfrom tensorflow.keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.layers.convolutional import Conv2D, MaxPooling2D \nfrom tensorflow.python.keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization","metadata":{"execution":{"iopub.status.busy":"2021-10-05T04:58:16.883863Z","iopub.execute_input":"2021-10-05T04:58:16.884183Z","iopub.status.idle":"2021-10-05T04:58:22.194497Z","shell.execute_reply.started":"2021-10-05T04:58:16.884088Z","shell.execute_reply":"2021-10-05T04:58:22.193723Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Load the data.\n\nDATASET_PATH = '../input/flowers-recognition/flowers'\n\ncategories = ['daisy', 'rose']","metadata":{"execution":{"iopub.status.busy":"2021-10-05T04:58:33.348564Z","iopub.execute_input":"2021-10-05T04:58:33.348831Z","iopub.status.idle":"2021-10-05T04:58:33.352356Z","shell.execute_reply.started":"2021-10-05T04:58:33.348802Z","shell.execute_reply":"2021-10-05T04:58:33.351663Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load the file names.\n\nfnames = []\nfor category in categories:\n    flower_folder = os.path.join(DATASET_PATH, category)\n    file_names = os.listdir(flower_folder)\n    full_path = [os.path.join(flower_folder, file_name) for file_name in file_names]\n    fnames.append(full_path)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T04:58:55.112265Z","iopub.execute_input":"2021-10-05T04:58:55.112988Z","iopub.status.idle":"2021-10-05T04:58:55.574328Z","shell.execute_reply.started":"2021-10-05T04:58:55.112951Z","shell.execute_reply":"2021-10-05T04:58:55.573568Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Determine length of each category.\n\nprint('length for each category:', [len(f) for f in fnames])","metadata":{"execution":{"iopub.status.busy":"2021-10-05T04:59:03.261407Z","iopub.execute_input":"2021-10-05T04:59:03.261849Z","iopub.status.idle":"2021-10-05T04:59:03.268300Z","shell.execute_reply.started":"2021-10-05T04:59:03.261806Z","shell.execute_reply":"2021-10-05T04:59:03.267545Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Split data into train and test.\n\ntrain_images = []\nval_images = []\nfor imgs in fnames:\n    train, test = train_test_split(imgs, train_size=0.8, test_size=0.2, random_state = 100)\n    train_images.append(train)\n    val_images.append(test)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T04:59:16.070822Z","iopub.execute_input":"2021-10-05T04:59:16.071094Z","iopub.status.idle":"2021-10-05T04:59:16.083953Z","shell.execute_reply.started":"2021-10-05T04:59:16.071065Z","shell.execute_reply":"2021-10-05T04:59:16.083203Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Load train images.\n\nimages_train = []\nfor names in train_images:\n    one_category_images = [cv2.imread(name) for name in names if (cv2.imread(name)) is not None]\n    images_train.append(one_category_images)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T04:59:43.937326Z","iopub.execute_input":"2021-10-05T04:59:43.937581Z","iopub.status.idle":"2021-10-05T04:59:57.440955Z","shell.execute_reply.started":"2021-10-05T04:59:43.937554Z","shell.execute_reply":"2021-10-05T04:59:57.440226Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Load test images.\n\nimages_test = []\nfor names in val_images:\n    one_category_images = [cv2.imread(name) for name in names if (cv2.imread(name)) is not None]\n    images_test.append(one_category_images)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T04:59:59.176167Z","iopub.execute_input":"2021-10-05T04:59:59.176826Z","iopub.status.idle":"2021-10-05T05:00:02.582615Z","shell.execute_reply.started":"2021-10-05T04:59:59.176790Z","shell.execute_reply":"2021-10-05T05:00:02.581873Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Determine shape of images in train.\n\nfor i,imgs in enumerate(images_train):\n    shapes = [img.shape for img in imgs]\n    widths = [shape[0] for shape in shapes]\n    heights = [shape[1] for shape in shapes]\n    print('%d,%d is the min shape for %s' % (np.min(widths), np.min(heights), categories[i]))","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:00:09.526680Z","iopub.execute_input":"2021-10-05T05:00:09.527236Z","iopub.status.idle":"2021-10-05T05:00:09.534680Z","shell.execute_reply.started":"2021-10-05T05:00:09.527201Z","shell.execute_reply":"2021-10-05T05:00:09.533774Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Determine shape of images in test.\n\nfor i,imgs in enumerate(images_test):\n    shapes = [img.shape for img in imgs]\n    widths = [shape[0] for shape in shapes]\n    heights = [shape[1] for shape in shapes]\n    print('%d,%d is the min shape for %s' % (np.min(widths), np.min(heights), categories[i]))","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:00:16.457741Z","iopub.execute_input":"2021-10-05T05:00:16.457986Z","iopub.status.idle":"2021-10-05T05:00:16.464640Z","shell.execute_reply.started":"2021-10-05T05:00:16.457959Z","shell.execute_reply":"2021-10-05T05:00:16.463720Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Create a function to convert BGR format to RGB format.\n\ndef cvtRGB(img):\n    return cv2.cvtColor(img.copy(), cv2.COLOR_BGR2RGB)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:00:24.437072Z","iopub.execute_input":"2021-10-05T05:00:24.437792Z","iopub.status.idle":"2021-10-05T05:00:24.442338Z","shell.execute_reply.started":"2021-10-05T05:00:24.437755Z","shell.execute_reply":"2021-10-05T05:00:24.441487Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Plotting images.\n\nplt.figure(figsize = (15,10))\nfor i, imgs in enumerate(images_train):\n    plt.subplot(2, 3, i+1)\n    idx = np.random.randint(len(imgs))\n    plt.imshow(cvtRGB(imgs[idx]))\n    plt.grid('off')\n    plt.title(categories[i] + ' ' + str(idx))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:00:29.915976Z","iopub.execute_input":"2021-10-05T05:00:29.916521Z","iopub.status.idle":"2021-10-05T05:00:30.320235Z","shell.execute_reply.started":"2021-10-05T05:00:29.916485Z","shell.execute_reply":"2021-10-05T05:00:30.319589Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Apply resize to all train images.\n\nimg_width, img_height = 256, 256\nresized_images_tr = []\nfor i,imgs in enumerate(images_train):\n    resized_images_tr.append([cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_CUBIC) for img in imgs])","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:00:53.330013Z","iopub.execute_input":"2021-10-05T05:00:53.330705Z","iopub.status.idle":"2021-10-05T05:00:53.757691Z","shell.execute_reply.started":"2021-10-05T05:00:53.330668Z","shell.execute_reply":"2021-10-05T05:00:53.756958Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Apply resize to all test images.\n\nimg_width, img_height = 256, 256\nresized_images_te = []\nfor i,imgs in enumerate(images_test):\n    resized_images_te.append([cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_CUBIC) for img in imgs])","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:01:02.182062Z","iopub.execute_input":"2021-10-05T05:01:02.182705Z","iopub.status.idle":"2021-10-05T05:01:02.309866Z","shell.execute_reply.started":"2021-10-05T05:01:02.182666Z","shell.execute_reply":"2021-10-05T05:01:02.309062Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Store resized_images_tr and resized_images_te in train_images and val_images respectively.\n\ntrain_images = resized_images_tr\nval_images = resized_images_te","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:02:17.582581Z","iopub.execute_input":"2021-10-05T05:02:17.583521Z","iopub.status.idle":"2021-10-05T05:02:17.587049Z","shell.execute_reply.started":"2021-10-05T05:02:17.583485Z","shell.execute_reply":"2021-10-05T05:02:17.586225Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Create labels for all images.\n\nlen_train_images = [len(imgs) for imgs in train_images]\nprint(len_train_images)\nprint('sum of train images:', np.sum(len_train_images))\ntrain_categories = np.zeros((np.sum(len_train_images)), dtype = 'uint8')\nfor i in range(5):\n    if i is 0:\n        train_categories[:len_train_images[i]] = i\n    else:\n        train_categories[np.sum(len_train_images[:i]):np.sum(len_train_images[:i+1])] = i\n        \nlen_val_images = [len(imgs) for imgs in val_images]\nprint(len_val_images)\nprint('sum of val_images:', np.sum(len_val_images))\nval_categories = np.zeros((np.sum(len_val_images)), dtype = 'uint8')\nfor i in range(5):\n    if i is 0:\n        val_categories[:len_val_images[i]] = i\n    else:\n        val_categories[np.sum(len_val_images[:i]):np.sum(len_val_images[:i+1])] = i","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:02:26.705982Z","iopub.execute_input":"2021-10-05T05:02:26.706676Z","iopub.status.idle":"2021-10-05T05:02:26.870842Z","shell.execute_reply.started":"2021-10-05T05:02:26.706640Z","shell.execute_reply":"2021-10-05T05:02:26.867198Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Convert images to numpy arrays.\n\ntmp_train_imgs = []\ntmp_val_imgs = []\nfor imgs in train_images:\n    tmp_train_imgs += imgs\nfor imgs in val_images:\n    tmp_val_imgs += imgs\ntrain_images = np.array(tmp_train_imgs)\nval_images = np.array(tmp_val_imgs)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:02:36.470983Z","iopub.execute_input":"2021-10-05T05:02:36.471265Z","iopub.status.idle":"2021-10-05T05:02:36.568666Z","shell.execute_reply.started":"2021-10-05T05:02:36.471233Z","shell.execute_reply":"2021-10-05T05:02:36.567887Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Convert class labels to binary class labels.\n\nprint('Before converting')\nprint('train data:', train_images.shape)\nprint('train labels:', train_categories.shape)\n\ntrain_data = train_images.astype('float32')\nval_data = val_images.astype('float32')\ntrain_labels = np_utils.to_categorical(train_categories, len(categories))\nval_labels = np_utils.to_categorical(val_categories, len(categories))\nprint()\nprint('After converting')\nprint('train data:', train_data.shape)\nprint('train labels:', train_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:02:43.194987Z","iopub.execute_input":"2021-10-05T05:02:43.195497Z","iopub.status.idle":"2021-10-05T05:02:43.502720Z","shell.execute_reply.started":"2021-10-05T05:02:43.195463Z","shell.execute_reply":"2021-10-05T05:02:43.501943Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Shuffle the data.\n\nseed = 100\nnp.random.seed(seed)\nnp.random.shuffle(train_data)\nnp.random.seed(seed)\nnp.random.shuffle(train_labels)\nnp.random.seed(seed)\nnp.random.shuffle(val_data)\nnp.random.seed(seed)\nnp.random.shuffle(val_labels)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:02:49.933886Z","iopub.execute_input":"2021-10-05T05:02:49.934698Z","iopub.status.idle":"2021-10-05T05:02:50.356173Z","shell.execute_reply.started":"2021-10-05T05:02:49.934660Z","shell.execute_reply":"2021-10-05T05:02:50.355417Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# View shape of train_data and test_data.\n\nprint('shape of train data:', train_data.shape)\nprint('shape of train labels:', train_labels.shape)\nprint('shape of val data:', val_data.shape)\nprint('shape of val labels:', val_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:02:57.132983Z","iopub.execute_input":"2021-10-05T05:02:57.133659Z","iopub.status.idle":"2021-10-05T05:02:57.139488Z","shell.execute_reply.started":"2021-10-05T05:02:57.133619Z","shell.execute_reply":"2021-10-05T05:02:57.138716Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### **Model Building**","metadata":{}},{"cell_type":"markdown","source":"### **1. Create a CNN model**","metadata":{}},{"cell_type":"code","source":"def create_model_from_scratch():\n\n    np.random.seed(1337)\n    model = Sequential()\n    model.add(Conv2D(32, (3,3), padding = 'same', input_shape = train_data.shape[1:], activation = 'relu', name = 'conv_1'))\n    model.add(Conv2D(32, (3,3), activation = 'relu', name = 'conv_2'))\n    model.add(MaxPooling2D(pool_size = (2,2), name = 'maxpool_1'))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(64, (3,3), padding = 'same', activation = 'relu', name = 'conv_3'))\n    model.add(Conv2D(64, (3,3), activation = 'relu', name = 'conv_4'))\n    model.add(MaxPooling2D(pool_size = (2,2), name = 'maxpool_2'))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(128, (3,3), padding = 'same', activation = 'relu', name = 'conv_5'))\n    model.add(Conv2D(128, (3,3), activation = 'relu', name = 'conv_6'))\n    model.add(MaxPooling2D(pool_size = (2,2), name = 'maxpool_3'))\n\n    model.add(Flatten())\n    model.add(Dense(512, activation = 'relu', name = 'dense_1'))\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation = 'relu', name = 'dense_2'))\n    model.add(Dense(len(categories), name = 'output'))\n    model.add(Activation('softmax'))\n\n    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc']) \n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:03:08.026346Z","iopub.execute_input":"2021-10-05T05:03:08.026632Z","iopub.status.idle":"2021-10-05T05:03:08.040364Z","shell.execute_reply.started":"2021-10-05T05:03:08.026603Z","shell.execute_reply":"2021-10-05T05:03:08.039640Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"### **2. Create a VGG19 model**","metadata":{}},{"cell_type":"code","source":"def create_model_from_VGG19():\n    \n    np.random.seed(1337)\n    model = VGG19(weights = \"imagenet\", include_top = False, input_shape = (img_width, img_height, 3))\n    \n    # Freezing the first 5 layers.\n    \n    for layer in model.layers[:1]:\n      layer.trainable = False\n      \n    # Adding custom Layers. \n    \n    x = model.output\n    x = Flatten()(x)\n    x = Dense(1024, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    x = Dense(1024, activation=\"relu\")(x)\n    predictions = Dense(len(categories), activation = \"softmax\")(x)\n    \n    # creating the final model.\n    \n    final_model = Model(inputs = model.input, outputs = predictions)\n    \n    final_model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc']) \n    \n    return final_model","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:03:26.850062Z","iopub.execute_input":"2021-10-05T05:03:26.850687Z","iopub.status.idle":"2021-10-05T05:03:26.860304Z","shell.execute_reply.started":"2021-10-05T05:03:26.850650Z","shell.execute_reply":"2021-10-05T05:03:26.859572Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### **3. Create ResNet50 model**","metadata":{}},{"cell_type":"code","source":"def create_model_from_ResNet50():\n\n    np.random.seed(1337)\n    model = Sequential()\n\n    model.add(ResNet50(include_top = False, pooling = 'avg', weights = 'imagenet'))\n    model.add(Flatten())\n    model.add(BatchNormalization())\n    model.add(Dense(2048, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dense(1024, activation = 'relu'))\n    model.add(BatchNormalization())\n    model.add(Dense(len(categories), activation = 'softmax'))\n\n    model.layers[0].trainable = False\n    \n    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['acc']) \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:27:59.590220Z","iopub.execute_input":"2021-10-05T05:27:59.590786Z","iopub.status.idle":"2021-10-05T05:27:59.597906Z","shell.execute_reply.started":"2021-10-05T05:27:59.590751Z","shell.execute_reply":"2021-10-05T05:27:59.597089Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# View model summary.\n\nmodel_scratch = create_model_from_scratch()\n\nmodel_scratch.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:04:19.872714Z","iopub.execute_input":"2021-10-05T05:04:19.872977Z","iopub.status.idle":"2021-10-05T05:04:22.013448Z","shell.execute_reply.started":"2021-10-05T05:04:19.872938Z","shell.execute_reply":"2021-10-05T05:04:22.012687Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# View model summary.\n\nmodel_VGG19 = create_model_from_VGG19()\n\nmodel_VGG19.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:04:29.816700Z","iopub.execute_input":"2021-10-05T05:04:29.816953Z","iopub.status.idle":"2021-10-05T05:04:30.562556Z","shell.execute_reply.started":"2021-10-05T05:04:29.816924Z","shell.execute_reply":"2021-10-05T05:04:30.561918Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# View model summary.\n\nmodel_ResNet50 = create_model_from_ResNet50()\n\nmodel_ResNet50.summary()","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:28:09.867564Z","iopub.execute_input":"2021-10-05T05:28:09.867818Z","iopub.status.idle":"2021-10-05T05:28:11.991736Z","shell.execute_reply.started":"2021-10-05T05:28:09.867790Z","shell.execute_reply":"2021-10-05T05:28:11.991078Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"### **Data Augmentation**","metadata":{}},{"cell_type":"code","source":"# Adding rescale, rotation_range, width_shift_range, height_shift_range,\n# shear_range, zoom_range, and horizontal flip to ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n    rescale = 1./255,\n    rotation_range = 40,\n    width_shift_range = 0.4,\n    height_shift_range = 0.4,\n    shear_range = 0.2,\n    zoom_range = 0.3,\n    horizontal_flip = True\n)\n\n\nval_datagen = ImageDataGenerator(\n    rescale = 1./255,\n    rotation_range = 40,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.2,\n    zoom_range = 0.2,\n    horizontal_flip = True\n)\n\n# Flow training images in batches of 32 using train_datagen generator.\n\ntrain_generator = train_datagen.flow(\n    train_data,\n    train_labels,\n    batch_size = 32\n)\n\nval_generator = val_datagen.flow(\n    val_data,\n    val_labels,\n    batch_size = 32\n)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:05:20.448348Z","iopub.execute_input":"2021-10-05T05:05:20.449053Z","iopub.status.idle":"2021-10-05T05:05:20.457926Z","shell.execute_reply.started":"2021-10-05T05:05:20.449015Z","shell.execute_reply":"2021-10-05T05:05:20.455247Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"### **Train the model**","metadata":{}},{"cell_type":"code","source":"batch_size = 32","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:05:43.128009Z","iopub.execute_input":"2021-10-05T05:05:43.128279Z","iopub.status.idle":"2021-10-05T05:05:43.132349Z","shell.execute_reply.started":"2021-10-05T05:05:43.128251Z","shell.execute_reply":"2021-10-05T05:05:43.131397Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nmodel_scratch_info = model_scratch.fit_generator(\n    generator = train_generator, \n    steps_per_epoch = len(train_data)/batch_size,   \n    epochs = 10, \n    validation_steps = len(val_data)/batch_size, \n    validation_data = val_generator, \n    verbose = 2\n)\n\nend = time.time()\nduration = end - start\nprint ('\\n model_scratch took %0.2f seconds (%0.1f minutes) to train for %d epochs'%(duration, duration/60, 10) )","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:06:09.828705Z","iopub.execute_input":"2021-10-05T05:06:09.828956Z","iopub.status.idle":"2021-10-05T05:09:38.098457Z","shell.execute_reply.started":"2021-10-05T05:06:09.828928Z","shell.execute_reply":"2021-10-05T05:09:38.097730Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nmodel_VGG19_info = model_VGG19.fit_generator(\n    generator = train_generator, \n    steps_per_epoch = len(train_data)/batch_size,   \n    epochs = 10, \n    validation_steps = len(val_data)/batch_size, \n    validation_data = val_generator,\n    verbose = 2\n)\n\nend = time.time()\nduration = end - start\nprint ('\\n model_VGG19 took %0.2f seconds (%0.1f minutes) to train for %d epochs'%(duration, duration/60, 10) )","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:09:52.463078Z","iopub.execute_input":"2021-10-05T05:09:52.463764Z","iopub.status.idle":"2021-10-05T05:13:36.970241Z","shell.execute_reply.started":"2021-10-05T05:09:52.463723Z","shell.execute_reply":"2021-10-05T05:13:36.969206Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"start = time.time()\n\nmodel_ResNet50_info = model_ResNet50.fit_generator(\n    generator = train_generator, \n    steps_per_epoch = len(train_data)/batch_size,   \n    epochs = 30, \n    validation_steps = len(val_data)/batch_size, \n    validation_data = val_generator, \n    verbose = 2\n)\n\nend = time.time()\nduration = end - start\nprint ('\\n model_ResNet50 took %0.2f seconds (%0.1f minutes) to train for %d epochs'%(duration, duration/60, 30))","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:29:09.555808Z","iopub.execute_input":"2021-10-05T05:29:09.556079Z","iopub.status.idle":"2021-10-05T05:39:44.230704Z","shell.execute_reply.started":"2021-10-05T05:29:09.556049Z","shell.execute_reply":"2021-10-05T05:39:44.229988Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"### **Predict the test data**","metadata":{}},{"cell_type":"code","source":"def predict_one_image(img, model):\n  img = cv2.resize(img, (img_width, img_height), interpolation = cv2.INTER_CUBIC)\n  img = np.reshape(img, (1, img_width, img_height, 3))\n  img = img/255.\n  pred = model.predict(img)\n  class_num = np.argmax(pred)\n  return class_num, np.max(pred)","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:24:51.543289Z","iopub.execute_input":"2021-10-05T05:24:51.543551Z","iopub.status.idle":"2021-10-05T05:24:51.548837Z","shell.execute_reply.started":"2021-10-05T05:24:51.543521Z","shell.execute_reply":"2021-10-05T05:24:51.548120Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Predict test data using scratch_model.\n\ntest_img = cv2.imread('../input/flowers-recognition/flowers/rose/15681454551_b6f73ce443_n.jpg')\npred, probability = predict_one_image(test_img, model_scratch)\nprint('%s %d%%' % (categories[pred], round(probability, 2) * 100))\n_, ax = plt.subplots(1)\nplt.imshow(cvtRGB(test_img))\n# Turn off tick labels\nax.set_yticklabels([])\nax.set_xticklabels([])\nplt.grid('off')\nplt.show()\n\n# Accuracy = 50%","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:25:56.189622Z","iopub.execute_input":"2021-10-05T05:25:56.189886Z","iopub.status.idle":"2021-10-05T05:25:56.664345Z","shell.execute_reply.started":"2021-10-05T05:25:56.189852Z","shell.execute_reply":"2021-10-05T05:25:56.661530Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Predict test data using VGG19 model.\n\ntest_img = cv2.imread('../input/flowers-recognition/flowers/rose/15681454551_b6f73ce443_n.jpg')\npred, probability = predict_one_image(test_img, model_VGG19)\nprint('%s %d%%' % (categories[pred], round(probability, 2) * 100))\n_, ax = plt.subplots(1)\nplt.imshow(cvtRGB(test_img))\n# Turn off tick labels\nax.set_yticklabels([])\nax.set_xticklabels([])\nplt.grid('off')\nplt.show()\n\n# Accuracy = 50%","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:26:17.745061Z","iopub.execute_input":"2021-10-05T05:26:17.745845Z","iopub.status.idle":"2021-10-05T05:26:18.366490Z","shell.execute_reply.started":"2021-10-05T05:26:17.745798Z","shell.execute_reply":"2021-10-05T05:26:18.365831Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Predict test data using ResNet50 model.\n\ntest_img = cv2.imread('../input/flowers-recognition/flowers/rose/15681454551_b6f73ce443_n.jpg')\npred, probability = predict_one_image(test_img, model_ResNet50)\nprint('%s %d%%' % (categories[pred], round(probability, 2) * 100))\n_, ax = plt.subplots(1)\nplt.imshow(cvtRGB(test_img))\n# Turn off tick labels\nax.set_yticklabels([])\nax.set_xticklabels([])\nplt.grid('off')\nplt.show()\n\n# Accuracy = 99%","metadata":{"execution":{"iopub.status.busy":"2021-10-05T05:40:03.514524Z","iopub.execute_input":"2021-10-05T05:40:03.514787Z","iopub.status.idle":"2021-10-05T05:40:04.555436Z","shell.execute_reply.started":"2021-10-05T05:40:03.514759Z","shell.execute_reply":"2021-10-05T05:40:04.554757Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"# **Conclusion:**\n\nResNet50 is performing best with an accuracy of 99% when compared to other models i.e scratch_model (Accuracy = 50%) and VGG19 model (Accuracy = 50%).","metadata":{}}]}